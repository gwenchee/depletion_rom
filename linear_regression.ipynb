{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert raw .dat file to  csv using curate_db.py\n",
    "# file has to exist in db/udb_1yr.dat\n",
    "# !python curate_db.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Curate Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = pd.read_csv('./curated.csv', index_col=0)\n",
    "\n",
    "# sift out pwrs\n",
    "all_dat = all_dat.loc[all_dat['reactor_type'] == 'PWR']  \n",
    "all_dat = sklearn.utils.shuffle(all_dat)\n",
    "# only get assemblies with enrichment bigger than 1.5 and bunrup higher than 10,000\n",
    "all_dat = all_dat.loc[(all_dat['init_enr'] > 1.5) & (all_dat['bu'] > 10000)]\n",
    "\n",
    "# separate training and testing set\n",
    "row_num = all_dat.shape[0]\n",
    "cutoff = int(row_num * 0.6)\n",
    "train_dat = all_dat.iloc[:cutoff, :]\n",
    "test_dat = all_dat.iloc[cutoff:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Isotopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u235': ['u-235'], 'bred_fissile': ['pu-239', 'u-233'], 'fp': ['zr-95', 'zr-93', 'ru-103', 'ru-106', 'sb-124', 'sb-125', 'nb-95', 'pd-107', 'pm-147', 'i-129', 'h-3', 'kr-85', 'nb-94', 'cs-134', 'cs-135', 'eu-152', 'cs-137', 'eu-154', 'eu-155', 'ag-108m', 'ag-110m', 'c-14', 'ce-144', 'y-90', 'tc-99', 'sm-151', 'se-79', 'sr-90', 'sn-126'], 'tru': ['pu-238', 'np-237', 'pu-240', 'pu-241', 'pu-244', 'pu-242', 'cm-248', 'cm-245', 'cm-244', 'cm-246', 'cm-247', 'am-241', 'am-243', 'cm-243', 'cm-242'], 'nottru': ['ra-226', 'pa-231', 'am-242m', 'cf-251', 'cf-249', 'ac-227', 'u-234', 'u-236', 'u-238', 'th-229', 'th-232', 'th-230', 'u-232']}\n"
     ]
    }
   ],
   "source": [
    "# get all the isotopes, sorted by A\n",
    "def get_name(f):\n",
    "    z = ''\n",
    "    for i in f:\n",
    "        if i.isalpha():\n",
    "            z += i\n",
    "    return z\n",
    "\n",
    "def get_a(f):\n",
    "    z = ''\n",
    "    for i in f:\n",
    "        if i.isdigit():\n",
    "            z += i\n",
    "    return int(z)\n",
    "\n",
    "iso_list = list(train_dat)[4:]\n",
    "# set the isotopes to categories:\n",
    "fp = []\n",
    "bred_fissile = []\n",
    "u235 = []\n",
    "nottru = []\n",
    "tru = []\n",
    "\n",
    "for iso in iso_list:\n",
    "    if iso == 'u-235':\n",
    "        u235.append(iso)\n",
    "    elif iso in ['pu-239', 'u-233']:\n",
    "        bred_fissile.append(iso)\n",
    "    elif get_a(iso) < 200:\n",
    "        fp.append(iso)\n",
    "    elif get_name(iso) in ['np', 'pu', 'am', 'cm']:\n",
    "        tru.append(iso)\n",
    "    else:\n",
    "        nottru.append(iso)\n",
    "\n",
    "category = {'u235': u235,\n",
    "            'bred_fissile': bred_fissile,\n",
    "            'fp': fp,\n",
    "            'tru': tru,\n",
    "            'nottru': nottru}\n",
    "\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define regression algorithms\n",
    "\n",
    "- From Sklearn:\n",
    "    - linear regression\n",
    "    - bayesian ridge\n",
    "    - huber regressor\n",
    "    - ridge\n",
    "    - lasso\n",
    "    - random forest\n",
    "- From Keras:\n",
    "    - neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {'lin_least_square': linear_model.LinearRegression,\n",
    "              'bayesianridge': linear_model.BayesianRidge,\n",
    "              'huberregressor': linear_model.HuberRegressor,\n",
    "              'ridge': linear_model.Ridge,\n",
    "              'lasso': linear_model.Lasso}\n",
    "    \n",
    "def linear_regression(algorithm, xtrain, ytrain, xtest, ytest):\n",
    "    al = algorithm()\n",
    "    model = al.fit(xtrain, ytrain)\n",
    "    model_err = (ytest - model.predict(xtest))**2\n",
    "    return model, model_err\n",
    "\n",
    "def poly_regression(xtrain, ytrain, xtest, ytest, deg=2):\n",
    "    poly = sklearn.preprocessing.PolynomialFeatures(degree=deg)\n",
    "    x_ = poly.fit_transform(xtrain)\n",
    "    predict_ = poly.fit_transform(xtest)\n",
    "    \n",
    "    # remove polynomial orders that isn't necessary (optional)\n",
    "    \n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(x_, ytrain)\n",
    "    \n",
    "    prediction = model.predict(predict_)\n",
    "    model_err = (ytest - prediction)**2\n",
    "    return model, model_err\n",
    "    \n",
    "\n",
    "def random_forest(xtrain, ytrain, xtest, ytest,\n",
    "                  estimators=1000, state=42):    \n",
    "    # Instantiate model with 1000 decision trees\n",
    "    model = RandomForestRegressor(n_estimators = estimators, random_state = state)\n",
    "    # Train the model on training data\n",
    "    model.fit(xtrain, ytrain)\n",
    "    model_err = (ytest - model.predict(xtest))**2\n",
    "    return model, model_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best model for each isotope\n",
    "Train model where:\n",
    "\n",
    "**features**: burnup, enrichment\n",
    "\n",
    "**target**: composition of isotope\n",
    "\n",
    "Find model that predicts the isotopic composition with smallest squared error for each isotope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_dat[['init_enr', 'bu']].as_matrix()\n",
    "x_test = test_dat[['init_enr', 'bu']].as_matrix()\n",
    "iso_err_dict = {}\n",
    "alg_dict = {}\n",
    "\n",
    "for iso in iso_list:\n",
    "    print(iso)\n",
    "    err_dict = {}\n",
    "    alg_buff = {}\n",
    "    y_train = np.asarray(train_dat[iso])\n",
    "    y_test = np.asarray(test_dat[iso])\n",
    "    \n",
    "    for key, val in algorithms.items():\n",
    "        try:\n",
    "            alg_buff[key], err_dict[key] = linear_regression(val, x_train, y_train, x_test, y_test)\n",
    "        except:\n",
    "            print('Cant use ', key)\n",
    "    alg_buff['random forest'], err_dict['random forest'] = random_forest(x_train, y_train, x_test, y_test)\n",
    "    alg_buff['poly2'], err_dict['poly2'] = poly_regression(x_train, y_train, x_test, y_test, deg=2)\n",
    "    alg_buff['poly3'], err_dict['poly3'] = poly_regression(x_train, y_train, x_test, y_test, deg=3)\n",
    "    alg_buff['poly4'], err_dict['poly4'] = poly_regression(x_train, y_train, x_test, y_test, deg=4)\n",
    "    alg_buff['poly5'], err_dict['poly5'] = poly_regression(x_train, y_train, x_test, y_test, deg=5)\n",
    "\n",
    "    \n",
    "    mean_err_dict = {}\n",
    "    for key, val in err_dict.items():\n",
    "        mean_err_dict[key] = np.abs(np.mean(val))\n",
    "    \n",
    "    chosen_alg = min(mean_err_dict, key=mean_err_dict.get)\n",
    "    print(chosen_alg)\n",
    "    err = err_dict[chosen_alg]\n",
    "    iso_err_dict[iso] = np.mean(err)\n",
    "    alg_dict[iso] = alg_buff[chosen_alg]\n",
    "    print(np.mean(err))\n",
    "    \n",
    "    plt.scatter(x_test[:,0], x_test[:,1], c=err)\n",
    "    plt.xlabel('Enrichment')\n",
    "    plt.ylabel('Burnup')\n",
    "    plt.colorbar()\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two things:\n",
    "- iso_err_dict\n",
    "    - key: isotope\n",
    "    - value: Mean error of model with test set\n",
    "- alg_dict\n",
    "    - key: isotope\n",
    "    - value: fitted model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in category.items():\n",
    "    err_list = []\n",
    "    for iso in val:\n",
    "        err_list.append(iso_err_dict[iso])\n",
    "        if np.abs(iso_err_dict[iso]) > 0.05:\n",
    "            print(iso, iso_err_dict[iso])\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.bar(val, err_list)    \n",
    "    plt.title(key)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle alg_dict to be used elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('lin_dep.pkl', 'wb')\n",
    "pickle.dump(alg_dict, f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
