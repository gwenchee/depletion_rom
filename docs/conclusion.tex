\section{Conclusion}

[plug about how it's `validated' against the trained dataset]
We cannot avoid the criticism that the model is validated
against the dataset used to train the model. However, the purpose
of this work is to create a model that can quickly reproduce the
database without having to distribute the database, which is proprietary
and large in size. On the other hand, the pickled file that contains
the model and data scaling objects is only 38.2 kB, meaning that it
can be easily distributed and applied in external software.

For the purpose of having an accessible
depletion model, this method holds promise.


future work:
a single model to go from
burnup, enrichment -> composition matrix
perhaps a neural network? preliminary results
show that they are worse. 