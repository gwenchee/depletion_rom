\section{Future Work}

A trained model only as good as the data it is trained on.
This work can be improved and expanded by generating
more comprehensive depletion data that covers a wider
range of enrichment and burnup ranges. An automated
code can run SCALE ORIGEN to perform depletion calculations
for a wide range of enrichment (e.g. 0.7 - 4.99 wt\%) and burnup (e.g. 0 - 80,000 MWd/MT),
for a single assembly design. Assumptions of criticality
and irradiation time should be made as well. The results
would then be parsed into a csv file and stored for
the training of a new model. This will allow better
prediction of the model for higher burnups and `fringe'
burnup-enrichment sets.

Methods used in this paper has potential to be expanded into more
complicated problems. For example, the method
could expand to depletion of \gls{MOX} fuels, taking
into account varying uranium and plutonium concentrations.
However, little data is available
for training a \gls{MOX} model, which means that a
data-generating process, consisting of a high-fidelity
depletion calculation of randomized \gls{MOX} fuel
compositions within acceptable ranges of reactor
criticality, similar to the process mentioned above,
will have to take place. After the data
is generated, the neural network model can be trained
to predict \gls{MOX} depletion.

Another interesting application of this method is for
\gls{MSR} parameter optimization. Current works on
\glspl{MSR} consist of optimizing non-core operating
parameters such as reprocessing scheme and flow rate.
The difficulty in optimizing these values is that the
fuel composition that is constantly flowing undergoes
transmutation, and fuel transmutation calculations
are usually computationally burdensome for \gls{MSR}
simulations, considering that fuel is depleted and
reprocessed continuously. Many \gls{MSR} models implement semi-continuous
models where the depletion-to-reprocessing time is
very short (usually 3 days), which makes an
\gls{MSR} lifetime simulation (if 60 years)
require \textasciitilde 7300 depletion calculations.
The computational burden
makes it impossible to perform brute-force methods
such as grid search of all possible parameters.
However, if a quick depletion calculation was possible
with a well-trained prediction model, the
computational burden will dramatically decrease.
However, problems with generating enough
training data, accuracy, and the model's ability to
extrapolate remain.