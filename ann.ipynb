{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and curate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = pd.read_csv('./curated.csv', index_col=0)\n",
    "\n",
    "# sift out pwrs\n",
    "all_dat = all_dat.loc[all_dat['reactor_type'] == 'PWR']  \n",
    "all_dat = sklearn.utils.shuffle(all_dat)\n",
    "# only get assemblies with enrichment bigger than 1.5 and bunrup higher than 10,000\n",
    "all_dat = all_dat.loc[(all_dat['init_enr'] > 1.5) & (all_dat['bu'] > 10000)]\n",
    "\n",
    "# separate training and testing set\n",
    "row_num = all_dat.shape[0]\n",
    "cutoff = int(row_num * 0.6)\n",
    "train_dat = all_dat.iloc[:cutoff, :]\n",
    "test_dat = all_dat.iloc[cutoff:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Isotopes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN algorithm ( + hyperparameter grid search)\n",
    "Below is an attempt to fit prediction of all isotopes in one Artificial Neural Network (ANN).\n",
    "First, the dataset is fit to an array of potential hyperparameters to find the best combination of hyperparameters for best predicting the isotope composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,5:].as_matrix()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xscaler = MinMaxScaler().fit(x)\n",
    "yscaler = MinMaxScaler().fit(y)\n",
    "xscale = xscaler.transform(x)\n",
    "yscale = yscaler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 12)                36        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 61)                549       \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(len(yscale[0]), activation='linear'))\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(xtrain, ytrain, epochs=200, batch_size=50, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())\n",
    "plt.plot(hist.history['loss'][5:])\n",
    "plt.plot(hist.history['val_loss'][5:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = np.array([[0.75008463, 0.54673347]])\n",
    "ynew = model.predict(xnew)\n",
    "print(ynew)\n",
    "print('x=%s, predicted=%s' % (xnew[0], yscaler.inverse_transform(ynew)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c3594b89377f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \"\"\"\n\u001b[1;32m    333\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "model.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "/home/teddy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (60,) but got array with shape (62,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c55a0dc798ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0muse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (60,) but got array with shape (62,)"
     ]
    }
   ],
   "source": [
    "# grid search to find best hyperparameter\n",
    "\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0,\n",
    "                 activation='relu', neurons=1,\n",
    "                 hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=2, activation=activation))\n",
    "    # consider putting in dropout?\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(60, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_percentage_error'])\n",
    "    return model\n",
    "\n",
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,4:]\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "param_grid = dict(batch_size=[10, 20, 40, 60, 80],\n",
    "                  epochs=[10, 50, 100, 200],\n",
    "                  optimizer=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "                  # learn rate and momentum implementation???\n",
    "                  activation = ['relu', 'softmax', 'softplus', 'softsign', 'tanh', 'linear'],\n",
    "                  neurons = [1, 5, 10, 20, 40, 80],\n",
    "                  hidden_layers = [0, 1, 3, 5, 10]\n",
    "                  )\n",
    "result_dict = {}\n",
    "\n",
    "# for every hyperparameter, run a grid search\n",
    "for param, param_list in param_grid.items():\n",
    "    print(param, '\\n\\n')\n",
    "    use = {param: param_list}\n",
    "    grid = GridSearchCV(estimator=model, param_grid=use)\n",
    "    grid_result = grid.fit(x, y)\n",
    "    result_dict[param] = (grid_result.best_score_, grid_result.best_params_)\n",
    "    # summarize results\n",
    "    print('Best: %f using %s' %(grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev. param in zip(means, stds, params):\n",
    "    #    print('%f (%f) with: %r' %(mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': (-37339.71153245486, {'batch_size': 20}),\n",
       " 'epochs': (-26118.439008011042, {'epochs': 100}),\n",
       " 'optimizer': (-64947.83971664397, {'optimizer': 'Adamax'}),\n",
       " 'activation': (-54298.19828140842, {'activation': 'softsign'}),\n",
       " 'neurons': (-72339.40957284004, {'neurons': 1}),\n",
       " 'hidden_layers': (-28876.054231980685, {'hidden_layers': 10})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7f0e9c2dd710>\n",
      "Train on 73185 samples, validate on 31366 samples\n",
      "Epoch 1/100\n",
      "73185/73185 [==============================] - 24s 334us/step - loss: 88177.8860 - mean_absolute_percentage_error: 88177.8860 - val_loss: 76297.6464 - val_mean_absolute_percentage_error: 76297.6464\n",
      "Epoch 2/100\n",
      "73185/73185 [==============================] - 18s 243us/step - loss: 71776.8624 - mean_absolute_percentage_error: 71776.8624 - val_loss: 66387.5748 - val_mean_absolute_percentage_error: 66387.5748\n",
      "Epoch 3/100\n",
      "73185/73185 [==============================] - 17s 227us/step - loss: 71383.8011 - mean_absolute_percentage_error: 71383.8011 - val_loss: 86997.0727 - val_mean_absolute_percentage_error: 86997.0727\n",
      "Epoch 4/100\n",
      "73185/73185 [==============================] - 16s 218us/step - loss: 72922.7693 - mean_absolute_percentage_error: 72922.7693 - val_loss: 66281.3289 - val_mean_absolute_percentage_error: 66281.3289\n",
      "Epoch 5/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 75174.1389 - mean_absolute_percentage_error: 75174.1389 - val_loss: 66275.5601 - val_mean_absolute_percentage_error: 66275.5601\n",
      "Epoch 6/100\n",
      "73185/73185 [==============================] - 16s 219us/step - loss: 73798.0947 - mean_absolute_percentage_error: 73798.0947 - val_loss: 73138.0659 - val_mean_absolute_percentage_error: 73138.0659\n",
      "Epoch 7/100\n",
      "73185/73185 [==============================] - 16s 218us/step - loss: 76586.4221 - mean_absolute_percentage_error: 76586.4221 - val_loss: 77035.5503 - val_mean_absolute_percentage_error: 77035.5503\n",
      "Epoch 8/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 75758.8037 - mean_absolute_percentage_error: 75758.8037 - val_loss: 83912.7832 - val_mean_absolute_percentage_error: 83912.7832\n",
      "Epoch 9/100\n",
      "73185/73185 [==============================] - 16s 219us/step - loss: 74695.9809 - mean_absolute_percentage_error: 74695.9809 - val_loss: 101447.4250 - val_mean_absolute_percentage_error: 101447.4250\n",
      "Epoch 10/100\n",
      "73185/73185 [==============================] - 17s 227us/step - loss: 73134.1447 - mean_absolute_percentage_error: 73134.1447 - val_loss: 77709.2228 - val_mean_absolute_percentage_error: 77709.2228\n",
      "Epoch 11/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 72889.9083 - mean_absolute_percentage_error: 72889.9083 - val_loss: 47298.8597 - val_mean_absolute_percentage_error: 47298.8597\n",
      "Epoch 12/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 69257.1391 - mean_absolute_percentage_error: 69257.1391 - val_loss: 74673.0227 - val_mean_absolute_percentage_error: 74673.0227\n",
      "Epoch 13/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70208.5364 - mean_absolute_percentage_error: 70208.5364 - val_loss: 72030.7407 - val_mean_absolute_percentage_error: 72030.7407\n",
      "Epoch 14/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70284.2412 - mean_absolute_percentage_error: 70284.2412 - val_loss: 75813.1071 - val_mean_absolute_percentage_error: 75813.1071\n",
      "Epoch 15/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71803.3386 - mean_absolute_percentage_error: 71803.3386 - val_loss: 92599.2900 - val_mean_absolute_percentage_error: 92599.2900\n",
      "Epoch 16/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 74179.7592 - mean_absolute_percentage_error: 74179.7592 - val_loss: 83694.9755 - val_mean_absolute_percentage_error: 83694.9755\n",
      "Epoch 17/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 73951.6685 - mean_absolute_percentage_error: 73951.6685 - val_loss: 87476.2474 - val_mean_absolute_percentage_error: 87476.2474\n",
      "Epoch 18/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 70901.6441 - mean_absolute_percentage_error: 70901.6441 - val_loss: 76895.3145 - val_mean_absolute_percentage_error: 76895.3145\n",
      "Epoch 19/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71297.1570 - mean_absolute_percentage_error: 71297.1570 - val_loss: 76300.2229 - val_mean_absolute_percentage_error: 76300.2229\n",
      "Epoch 20/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71703.4390 - mean_absolute_percentage_error: 71703.4390 - val_loss: 70406.9166 - val_mean_absolute_percentage_error: 70406.9166\n",
      "Epoch 21/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73554.1439 - mean_absolute_percentage_error: 73554.1439 - val_loss: 79254.5046 - val_mean_absolute_percentage_error: 79254.5046\n",
      "Epoch 22/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72640.0529 - mean_absolute_percentage_error: 72640.0529 - val_loss: 80725.0438 - val_mean_absolute_percentage_error: 80725.0438\n",
      "Epoch 23/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 70316.3832 - mean_absolute_percentage_error: 70316.3832 - val_loss: 68550.6065 - val_mean_absolute_percentage_error: 68550.6065\n",
      "Epoch 24/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71506.9705 - mean_absolute_percentage_error: 71506.9705 - val_loss: 61941.9341 - val_mean_absolute_percentage_error: 61941.9341\n",
      "Epoch 25/100\n",
      "73185/73185 [==============================] - 16s 216us/step - loss: 72851.8786 - mean_absolute_percentage_error: 72851.8786 - val_loss: 82948.3677 - val_mean_absolute_percentage_error: 82948.3677\n",
      "Epoch 26/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72968.4548 - mean_absolute_percentage_error: 72968.4548 - val_loss: 80020.2702 - val_mean_absolute_percentage_error: 80020.2702\n",
      "Epoch 27/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72850.2824 - mean_absolute_percentage_error: 72850.2824 - val_loss: 75912.4180 - val_mean_absolute_percentage_error: 75912.4180\n",
      "Epoch 28/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73371.3635 - mean_absolute_percentage_error: 73371.3635 - val_loss: 67047.2809 - val_mean_absolute_percentage_error: 67047.2809\n",
      "Epoch 29/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 75547.5171 - mean_absolute_percentage_error: 75547.5171 - val_loss: 83583.9931 - val_mean_absolute_percentage_error: 83583.9931\n",
      "Epoch 30/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74239.4051 - mean_absolute_percentage_error: 74239.4051 - val_loss: 68528.3354 - val_mean_absolute_percentage_error: 68528.3354\n",
      "Epoch 31/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 71355.5589 - mean_absolute_percentage_error: 71355.5589 - val_loss: 60007.3089 - val_mean_absolute_percentage_error: 60007.3089\n",
      "Epoch 32/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72528.3649 - mean_absolute_percentage_error: 72528.3649 - val_loss: 86829.5471 - val_mean_absolute_percentage_error: 86829.5471\n",
      "Epoch 33/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72466.2313 - mean_absolute_percentage_error: 72466.2313 - val_loss: 87147.3809 - val_mean_absolute_percentage_error: 87147.3809\n",
      "Epoch 34/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71738.2817 - mean_absolute_percentage_error: 71738.2817 - val_loss: 62230.3339 - val_mean_absolute_percentage_error: 62230.3339\n",
      "Epoch 35/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 73849.2161 - mean_absolute_percentage_error: 73849.2161 - val_loss: 76137.6067 - val_mean_absolute_percentage_error: 76137.6067\n",
      "Epoch 36/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69923.9724 - mean_absolute_percentage_error: 69923.9724 - val_loss: 84789.3068 - val_mean_absolute_percentage_error: 84789.3068\n",
      "Epoch 37/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68236.4944 - mean_absolute_percentage_error: 68236.4944 - val_loss: 59130.9267 - val_mean_absolute_percentage_error: 59130.9267\n",
      "Epoch 38/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68196.5417 - mean_absolute_percentage_error: 68196.5417 - val_loss: 60015.2813 - val_mean_absolute_percentage_error: 60015.2813\n",
      "Epoch 39/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68745.6717 - mean_absolute_percentage_error: 68745.6717 - val_loss: 100072.1471 - val_mean_absolute_percentage_error: 100072.1471\n",
      "Epoch 40/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 68765.0778 - mean_absolute_percentage_error: 68765.0778 - val_loss: 71391.0159 - val_mean_absolute_percentage_error: 71391.0159\n",
      "Epoch 41/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69671.2282 - mean_absolute_percentage_error: 69671.2282 - val_loss: 72415.5808 - val_mean_absolute_percentage_error: 72415.5808\n",
      "Epoch 42/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 69786.3615 - mean_absolute_percentage_error: 69786.3615 - val_loss: 81661.7223 - val_mean_absolute_percentage_error: 81661.7223\n",
      "Epoch 43/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71513.1146 - mean_absolute_percentage_error: 71513.1146 - val_loss: 70954.3089 - val_mean_absolute_percentage_error: 70954.3089\n",
      "Epoch 44/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70578.9827 - mean_absolute_percentage_error: 70578.9827 - val_loss: 83601.1950 - val_mean_absolute_percentage_error: 83601.1950\n",
      "Epoch 45/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71412.6494 - mean_absolute_percentage_error: 71412.6494 - val_loss: 93161.5678 - val_mean_absolute_percentage_error: 93161.5678\n",
      "Epoch 46/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71017.8248 - mean_absolute_percentage_error: 71017.8248 - val_loss: 78061.4125 - val_mean_absolute_percentage_error: 78061.4125\n",
      "Epoch 47/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71695.7787 - mean_absolute_percentage_error: 71695.7787 - val_loss: 95129.0020 - val_mean_absolute_percentage_error: 95129.0020\n",
      "Epoch 48/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72262.0495 - mean_absolute_percentage_error: 72262.0495 - val_loss: 82658.0063 - val_mean_absolute_percentage_error: 82658.0063\n",
      "Epoch 49/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73170.1839 - mean_absolute_percentage_error: 73170.1839 - val_loss: 62144.9654 - val_mean_absolute_percentage_error: 62144.9654\n",
      "Epoch 50/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72412.2551 - mean_absolute_percentage_error: 72412.2551 - val_loss: 78507.2766 - val_mean_absolute_percentage_error: 78507.2766\n",
      "Epoch 51/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71455.0052 - mean_absolute_percentage_error: 71455.0052 - val_loss: 83298.1384 - val_mean_absolute_percentage_error: 83298.1384\n",
      "Epoch 52/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72617.8439 - mean_absolute_percentage_error: 72617.8439 - val_loss: 56917.1428 - val_mean_absolute_percentage_error: 56917.1428\n",
      "Epoch 53/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 73113.9897 - mean_absolute_percentage_error: 73113.9897 - val_loss: 71171.4638 - val_mean_absolute_percentage_error: 71171.4638\n",
      "Epoch 54/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72640.1208 - mean_absolute_percentage_error: 72640.1208 - val_loss: 63341.6959 - val_mean_absolute_percentage_error: 63341.6959\n",
      "Epoch 55/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74744.5418 - mean_absolute_percentage_error: 74744.5418 - val_loss: 61852.4458 - val_mean_absolute_percentage_error: 61852.4458\n",
      "Epoch 56/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73006.9006 - mean_absolute_percentage_error: 73006.9006 - val_loss: 84960.1659 - val_mean_absolute_percentage_error: 84960.1659\n",
      "Epoch 57/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 73384.8217 - mean_absolute_percentage_error: 73384.8217 - val_loss: 57499.4290 - val_mean_absolute_percentage_error: 57499.4290\n",
      "Epoch 58/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 70959.5627 - mean_absolute_percentage_error: 70959.5627 - val_loss: 74756.7736 - val_mean_absolute_percentage_error: 74756.7736\n",
      "Epoch 59/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74050.7578 - mean_absolute_percentage_error: 74050.7578 - val_loss: 83979.7247 - val_mean_absolute_percentage_error: 83979.7247\n",
      "Epoch 60/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 73595.4047 - mean_absolute_percentage_error: 73595.4047 - val_loss: 65352.4208 - val_mean_absolute_percentage_error: 65352.4208\n",
      "Epoch 61/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73932.6425 - mean_absolute_percentage_error: 73932.6425 - val_loss: 67093.5760 - val_mean_absolute_percentage_error: 67093.5760\n",
      "Epoch 62/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73824.9415 - mean_absolute_percentage_error: 73824.9415 - val_loss: 97635.1258 - val_mean_absolute_percentage_error: 97635.1258\n",
      "Epoch 63/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73238.7050 - mean_absolute_percentage_error: 73238.7050 - val_loss: 66329.3939 - val_mean_absolute_percentage_error: 66329.3939\n",
      "Epoch 64/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71972.0366 - mean_absolute_percentage_error: 71972.0366 - val_loss: 51382.6440 - val_mean_absolute_percentage_error: 51382.6440\n",
      "Epoch 65/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68715.4248 - mean_absolute_percentage_error: 68715.4248 - val_loss: 83887.5295 - val_mean_absolute_percentage_error: 83887.5295\n",
      "Epoch 66/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69422.0180 - mean_absolute_percentage_error: 69422.0180 - val_loss: 70328.8957 - val_mean_absolute_percentage_error: 70328.8957\n",
      "Epoch 67/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70268.2656 - mean_absolute_percentage_error: 70268.2656 - val_loss: 85864.2286 - val_mean_absolute_percentage_error: 85864.2286\n",
      "Epoch 68/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69692.0971 - mean_absolute_percentage_error: 69692.0971 - val_loss: 63615.2444 - val_mean_absolute_percentage_error: 63615.2444\n",
      "Epoch 69/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71240.0152 - mean_absolute_percentage_error: 71240.0152 - val_loss: 82727.7221 - val_mean_absolute_percentage_error: 82727.7221\n",
      "Epoch 70/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70035.1911 - mean_absolute_percentage_error: 70035.1911 - val_loss: 71092.8966 - val_mean_absolute_percentage_error: 71092.8966\n",
      "Epoch 71/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71171.0975 - mean_absolute_percentage_error: 71171.0975 - val_loss: 60215.3691 - val_mean_absolute_percentage_error: 60215.3691\n",
      "Epoch 72/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70054.0061 - mean_absolute_percentage_error: 70054.0061 - val_loss: 84827.7476 - val_mean_absolute_percentage_error: 84827.7476\n",
      "Epoch 73/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70402.0413 - mean_absolute_percentage_error: 70402.0413 - val_loss: 67860.1209 - val_mean_absolute_percentage_error: 67860.1209\n",
      "Epoch 74/100\n",
      "73185/73185 [==============================] - 15s 199us/step - loss: 70098.3934 - mean_absolute_percentage_error: 70098.3934 - val_loss: 74515.4638 - val_mean_absolute_percentage_error: 74515.4638\n",
      "Epoch 75/100\n",
      "73185/73185 [==============================] - 15s 203us/step - loss: 70723.3444 - mean_absolute_percentage_error: 70723.3444 - val_loss: 56020.7061 - val_mean_absolute_percentage_error: 56020.7061\n",
      "Epoch 76/100\n",
      "73185/73185 [==============================] - 15s 205us/step - loss: 70949.9630 - mean_absolute_percentage_error: 70949.9630 - val_loss: 69787.9597 - val_mean_absolute_percentage_error: 69787.9597\n",
      "Epoch 77/100\n",
      "73185/73185 [==============================] - 14s 191us/step - loss: 70664.9296 - mean_absolute_percentage_error: 70664.9296 - val_loss: 83353.5864 - val_mean_absolute_percentage_error: 83353.5864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "73185/73185 [==============================] - 15s 208us/step - loss: 70375.6989 - mean_absolute_percentage_error: 70375.6989 - val_loss: 74180.0553 - val_mean_absolute_percentage_error: 74180.0553\n",
      "Epoch 79/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70814.4295 - mean_absolute_percentage_error: 70814.4295 - val_loss: 85027.3690 - val_mean_absolute_percentage_error: 85027.3690\n",
      "Epoch 80/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70454.8263 - mean_absolute_percentage_error: 70454.8263 - val_loss: 86863.8476 - val_mean_absolute_percentage_error: 86863.8476\n",
      "Epoch 81/100\n",
      "73185/73185 [==============================] - 15s 210us/step - loss: 70866.0745 - mean_absolute_percentage_error: 70866.0745 - val_loss: 90682.0947 - val_mean_absolute_percentage_error: 90682.0947\n",
      "Epoch 82/100\n",
      "73185/73185 [==============================] - 15s 210us/step - loss: 69912.6575 - mean_absolute_percentage_error: 69912.6575 - val_loss: 52640.3338 - val_mean_absolute_percentage_error: 52640.3338\n",
      "Epoch 83/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70539.1420 - mean_absolute_percentage_error: 70539.1420 - val_loss: 73446.2364 - val_mean_absolute_percentage_error: 73446.2364\n",
      "Epoch 84/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69792.7883 - mean_absolute_percentage_error: 69792.7883 - val_loss: 70524.7690 - val_mean_absolute_percentage_error: 70524.7690\n",
      "Epoch 85/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 68409.2679 - mean_absolute_percentage_error: 68409.2679 - val_loss: 71899.2593 - val_mean_absolute_percentage_error: 71899.2593\n",
      "Epoch 86/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70721.7637 - mean_absolute_percentage_error: 70721.7637 - val_loss: 71310.7056 - val_mean_absolute_percentage_error: 71310.7056\n",
      "Epoch 87/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70228.1081 - mean_absolute_percentage_error: 70228.1081 - val_loss: 72461.8812 - val_mean_absolute_percentage_error: 72461.8812\n",
      "Epoch 88/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 68600.9001 - mean_absolute_percentage_error: 68600.9001 - val_loss: 75261.6803 - val_mean_absolute_percentage_error: 75261.6803\n",
      "Epoch 89/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70094.5149 - mean_absolute_percentage_error: 70094.5149 - val_loss: 61978.9363 - val_mean_absolute_percentage_error: 61978.9363\n",
      "Epoch 90/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 68293.3034 - mean_absolute_percentage_error: 68293.3034 - val_loss: 52865.1689 - val_mean_absolute_percentage_error: 52865.1689\n",
      "Epoch 91/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 66767.7737 - mean_absolute_percentage_error: 66767.7737 - val_loss: 79177.7573 - val_mean_absolute_percentage_error: 79177.7573\n",
      "Epoch 92/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70571.6620 - mean_absolute_percentage_error: 70571.6620 - val_loss: 94018.4021 - val_mean_absolute_percentage_error: 94018.4021\n",
      "Epoch 93/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69951.4603 - mean_absolute_percentage_error: 69951.4603 - val_loss: 57747.0817 - val_mean_absolute_percentage_error: 57747.0817\n",
      "Epoch 94/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70345.4998 - mean_absolute_percentage_error: 70345.4998 - val_loss: 64859.2549 - val_mean_absolute_percentage_error: 64859.2549\n",
      "Epoch 95/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70635.7272 - mean_absolute_percentage_error: 70635.7272 - val_loss: 90067.0441 - val_mean_absolute_percentage_error: 90067.0441\n",
      "Epoch 96/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69202.2595 - mean_absolute_percentage_error: 69202.2595 - val_loss: 63398.4961 - val_mean_absolute_percentage_error: 63398.4961\n",
      "Epoch 97/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69016.9767 - mean_absolute_percentage_error: 69016.9767 - val_loss: 72729.9435 - val_mean_absolute_percentage_error: 72729.9435\n",
      "Epoch 98/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71753.9803 - mean_absolute_percentage_error: 71753.9803 - val_loss: 66843.0989 - val_mean_absolute_percentage_error: 66843.0989\n",
      "Epoch 99/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72365.2606 - mean_absolute_percentage_error: 72365.2606 - val_loss: 101087.6113 - val_mean_absolute_percentage_error: 101087.6113\n",
      "Epoch 100/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 72426.1962 - mean_absolute_percentage_error: 72426.1962 - val_loss: 81406.2984 - val_mean_absolute_percentage_error: 81406.2984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.evaluate of <keras.models.Sequential object at 0x7f0e9c2dd710>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the best:\n",
    "def get_val(dictionary, key):\n",
    "    return dictionary[key][1][key]\n",
    "batch_size = get_val(result_dict, 'batch_size')\n",
    "epochs = get_val(result_dict, 'epochs')\n",
    "optimizer = get_val(result_dict, 'optimizer')\n",
    "activation = get_val(result_dict, 'activation')\n",
    "neurons = get_val(result_dict, 'neurons')\n",
    "hidden_layer = get_val(result_dict, 'hidden_layers')\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0,\n",
    "                 activation='relu', neurons=1,\n",
    "                 hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=2, activation=activation))\n",
    "    # consider putting in dropout?\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(60, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_percentage_error'])\n",
    "    return model\n",
    "\n",
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,4:]\n",
    "\n",
    "model =  create_model(optimizer=optimizer, activation=activation, neurons=neurons,\n",
    "                     hidden_layers=hidden_layer)\n",
    "print(model)\n",
    "model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_split=0.3)\n",
    "model.evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = x[300]\n",
    "prediction = model.predict(x)\n",
    "iso_list = list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "\n",
    "for indx, val in enumerate(prediction[300]):\n",
    "    err.append((val-np.array(y.iloc[300])[indx]) / np.array(y.iloc[300])[indx])\n",
    "    print(iso_list[indx], '\\t\\t', val, '\\t\\t', np.array(y.iloc[300])[indx])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "    \n",
    "for indx, val in enumerate(err):\n",
    "    print(iso_list[indx], '\\t', err[indx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
