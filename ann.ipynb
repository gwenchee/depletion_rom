{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and curate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = pd.read_csv('./curated.csv', index_col=0)\n",
    "\n",
    "# sift out pwrs\n",
    "all_dat = all_dat.loc[all_dat['reactor_type'] == 'PWR']  \n",
    "all_dat = sklearn.utils.shuffle(all_dat)\n",
    "# only get assemblies with enrichment bigger than 1.5 and bunrup higher than 10,000\n",
    "all_dat = all_dat.loc[(all_dat['init_enr'] > 1.5) & (all_dat['bu'] > 10000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-05-07'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(all_dat['evaluation_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Isotopes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN algorithm ( + hyperparameter grid search)\n",
    "Below is an attempt to fit prediction of all isotopes in one Artificial Neural Network (ANN).\n",
    "First, the dataset is fit to an array of potential hyperparameters to find the best combination of hyperparameters for best predicting the isotope composition.\n",
    "\n",
    "\n",
    "try:\n",
    "- sigmoid for output layer (currently linear)\n",
    "- dropout\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,5:].as_matrix()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xscaler = MinMaxScaler().fit(x)\n",
    "yscaler = MinMaxScaler().fit(y)\n",
    "xscale = xscaler.transform(x)\n",
    "yscale = yscaler.transform(y)\n",
    "\n",
    "iso_list = list(all_dat.iloc[:, 5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104551, 2)\n",
      "(104551, 61)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(xscale))\n",
    "print(np.shape(yscale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "69700/69700 [==============================] - 6s 87us/step - loss: 0.0206 - mean_squared_error: 0.0206 - mean_absolute_error: 0.1070\n",
      "Epoch 2/150\n",
      "69700/69700 [==============================] - 5s 68us/step - loss: 0.0032 - mean_squared_error: 0.0032 - mean_absolute_error: 0.0397\n",
      "Epoch 3/150\n",
      "69700/69700 [==============================] - 5s 66us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0342\n",
      "Epoch 4/150\n",
      "69700/69700 [==============================] - 5s 67us/step - loss: 0.0026 - mean_squared_error: 0.0026 - mean_absolute_error: 0.0330\n",
      "Epoch 5/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0314\n",
      "Epoch 6/150\n",
      "69700/69700 [==============================] - 7s 104us/step - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0291\n",
      "Epoch 7/150\n",
      "69700/69700 [==============================] - 5s 72us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0274\n",
      "Epoch 8/150\n",
      "69700/69700 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0266\n",
      "Epoch 9/150\n",
      "69700/69700 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0262\n",
      "Epoch 10/150\n",
      "69700/69700 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 11/150\n",
      "69700/69700 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 12/150\n",
      "69700/69700 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 13/150\n",
      "69700/69700 [==============================] - 7s 106us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 14/150\n",
      "69700/69700 [==============================] - 7s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 15/150\n",
      "69700/69700 [==============================] - 7s 101us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 16/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 17/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 18/150\n",
      "69700/69700 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 19/150\n",
      "69700/69700 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 20/150\n",
      "69700/69700 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 21/150\n",
      "69700/69700 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 22/150\n",
      "69700/69700 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 23/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 24/150\n",
      "69700/69700 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 25/150\n",
      "69700/69700 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 26/150\n",
      "69700/69700 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 27/150\n",
      "69700/69700 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 28/150\n",
      "69700/69700 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 29/150\n",
      "69700/69700 [==============================] - 8s 121us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 30/150\n",
      "69700/69700 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 31/150\n",
      "69700/69700 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 32/150\n",
      "69700/69700 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 33/150\n",
      "69700/69700 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 34/150\n",
      "69700/69700 [==============================] - 4s 56us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 35/150\n",
      "69700/69700 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 36/150\n",
      "69700/69700 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 37/150\n",
      "69700/69700 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 38/150\n",
      "69700/69700 [==============================] - 5s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 39/150\n",
      "69700/69700 [==============================] - 8s 111us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 40/150\n",
      "69700/69700 [==============================] - 7s 105us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 41/150\n",
      "69700/69700 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 42/150\n",
      "69700/69700 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 43/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 44/150\n",
      "69700/69700 [==============================] - 9s 128us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 45/150\n",
      "69700/69700 [==============================] - 8s 117us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 46/150\n",
      "69700/69700 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 47/150\n",
      "69700/69700 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 48/150\n",
      "69700/69700 [==============================] - 7s 99us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 49/150\n",
      "69700/69700 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 50/150\n",
      "69700/69700 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 51/150\n",
      "69700/69700 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 52/150\n",
      "69700/69700 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 53/150\n",
      "69700/69700 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 54/150\n",
      "69700/69700 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 55/150\n",
      "69700/69700 [==============================] - 4s 52us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 56/150\n",
      "69700/69700 [==============================] - 4s 52us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 57/150\n",
      "69700/69700 [==============================] - 4s 53us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 58/150\n",
      "69700/69700 [==============================] - 4s 55us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 59/150\n",
      "69700/69700 [==============================] - 3s 50us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 60/150\n",
      "69700/69700 [==============================] - 4s 50us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 61/150\n",
      "69700/69700 [==============================] - 4s 54us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 62/150\n",
      "69700/69700 [==============================] - 4s 52us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 63/150\n",
      "69700/69700 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 64/150\n",
      "69700/69700 [==============================] - 7s 97us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 65/150\n",
      "69700/69700 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 66/150\n",
      "69700/69700 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 67/150\n",
      "69700/69700 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 68/150\n",
      "69700/69700 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 69/150\n",
      "69700/69700 [==============================] - 4s 54us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 70/150\n",
      "69700/69700 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 71/150\n",
      "69700/69700 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 72/150\n",
      "69700/69700 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 73/150\n",
      "69700/69700 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 74/150\n",
      "69700/69700 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 75/150\n",
      "69700/69700 [==============================] - 4s 52us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 76/150\n",
      "69700/69700 [==============================] - 4s 52us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 77/150\n",
      "69700/69700 [==============================] - 4s 56us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 78/150\n",
      "69700/69700 [==============================] - 4s 54us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 79/150\n",
      "69700/69700 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 80/150\n",
      "69700/69700 [==============================] - 4s 55us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 81/150\n",
      "69700/69700 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 82/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 83/150\n",
      "69700/69700 [==============================] - 4s 56us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 84/150\n",
      "69700/69700 [==============================] - 4s 54us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 85/150\n",
      "69700/69700 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 86/150\n",
      "69700/69700 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 87/150\n",
      "69700/69700 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 88/150\n",
      "69700/69700 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 89/150\n",
      "69700/69700 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 90/150\n",
      "69700/69700 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 91/150\n",
      "69700/69700 [==============================] - 5s 66us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 92/150\n",
      "69700/69700 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 93/150\n",
      "69700/69700 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 94/150\n",
      "69700/69700 [==============================] - 4s 55us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 95/150\n",
      "69700/69700 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 96/150\n",
      "69700/69700 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 97/150\n",
      "69700/69700 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 98/150\n",
      "69700/69700 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 99/150\n",
      "69700/69700 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 100/150\n",
      "69700/69700 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 101/150\n",
      "69700/69700 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 102/150\n",
      "69700/69700 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 103/150\n",
      "69700/69700 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 104/150\n",
      "69700/69700 [==============================] - 7s 104us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 105/150\n",
      "69700/69700 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 106/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 107/150\n",
      "69700/69700 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 108/150\n",
      "69700/69700 [==============================] - 8s 112us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 109/150\n",
      "69700/69700 [==============================] - 7s 97us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 110/150\n",
      "69700/69700 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 111/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 112/150\n",
      "69700/69700 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 113/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 114/150\n",
      "69700/69700 [==============================] - 7s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 115/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 116/150\n",
      "69700/69700 [==============================] - 7s 105us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 117/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 118/150\n",
      "69700/69700 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 119/150\n",
      "69700/69700 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 120/150\n",
      "69700/69700 [==============================] - 5s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 121/150\n",
      "69700/69700 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 122/150\n",
      "69700/69700 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 123/150\n",
      "69700/69700 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 124/150\n",
      "69700/69700 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 125/150\n",
      "69700/69700 [==============================] - 7s 102us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 126/150\n",
      "69700/69700 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 127/150\n",
      "69700/69700 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 128/150\n",
      "69700/69700 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 129/150\n",
      "69700/69700 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 130/150\n",
      "69700/69700 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 131/150\n",
      "69700/69700 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 132/150\n",
      "69700/69700 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 133/150\n",
      "69700/69700 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 134/150\n",
      "69700/69700 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 135/150\n",
      "69700/69700 [==============================] - 6s 89us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0257\n",
      "Epoch 136/150\n",
      "69700/69700 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 137/150\n",
      "69700/69700 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 138/150\n",
      "69700/69700 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 139/150\n",
      "69700/69700 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 140/150\n",
      "69700/69700 [==============================] - 6s 93us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 141/150\n",
      "69700/69700 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 142/150\n",
      "69700/69700 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 143/150\n",
      "69700/69700 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 144/150\n",
      "69700/69700 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 145/150\n",
      "69700/69700 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 146/150\n",
      "69700/69700 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 147/150\n",
      "69700/69700 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 148/150\n",
      "69700/69700 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 149/150\n",
      "69700/69700 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "Epoch 150/150\n",
      "69700/69700 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0256\n",
      "34851/34851 [==============================] - 2s 65us/step\n",
      "mean_squared_error: 0.19%\n",
      "Epoch 1/150\n",
      "69701/69701 [==============================] - 6s 93us/step - loss: 0.0202 - mean_squared_error: 0.0202 - mean_absolute_error: 0.1044\n",
      "Epoch 2/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0030 - mean_squared_error: 0.0030 - mean_absolute_error: 0.0378\n",
      "Epoch 3/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0339\n",
      "Epoch 4/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0329\n",
      "Epoch 5/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0309\n",
      "Epoch 6/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0290\n",
      "Epoch 7/150\n",
      "69701/69701 [==============================] - 5s 75us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0278\n",
      "Epoch 8/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0273\n",
      "Epoch 9/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270\n",
      "Epoch 10/150\n",
      "69701/69701 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270\n",
      "Epoch 11/150\n",
      "69701/69701 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 12/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 13/150\n",
      "69701/69701 [==============================] - 7s 100us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 14/150\n",
      "69701/69701 [==============================] - 7s 107us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 15/150\n",
      "69701/69701 [==============================] - 8s 118us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "69701/69701 [==============================] - 8s 113us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 17/150\n",
      "69701/69701 [==============================] - 7s 103us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 18/150\n",
      "69701/69701 [==============================] - 8s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 19/150\n",
      "69701/69701 [==============================] - 7s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 20/150\n",
      "69701/69701 [==============================] - 6s 93us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 21/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 22/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 23/150\n",
      "69701/69701 [==============================] - 7s 102us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 24/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 25/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 26/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 27/150\n",
      "69701/69701 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 28/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 29/150\n",
      "69701/69701 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 30/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 31/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 32/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 33/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 34/150\n",
      "69701/69701 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 35/150\n",
      "69701/69701 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 36/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 37/150\n",
      "69701/69701 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 38/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 39/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 40/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 41/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 42/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 43/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 44/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 45/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 46/150\n",
      "69701/69701 [==============================] - 7s 99us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 47/150\n",
      "69701/69701 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 48/150\n",
      "69701/69701 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 49/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 50/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 51/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 52/150\n",
      "69701/69701 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 53/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 54/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 55/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 56/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 57/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 58/150\n",
      "69701/69701 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 59/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 60/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 61/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 62/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 63/150\n",
      "69701/69701 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 64/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 65/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 66/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 67/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 68/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 69/150\n",
      "69701/69701 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 70/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 71/150\n",
      "69701/69701 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 72/150\n",
      "69701/69701 [==============================] - 7s 105us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 73/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 74/150\n",
      "69701/69701 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 75/150\n",
      "69701/69701 [==============================] - 8s 120us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 76/150\n",
      "69701/69701 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 77/150\n",
      "69701/69701 [==============================] - 7s 101us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 78/150\n",
      "69701/69701 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 79/150\n",
      "69701/69701 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 80/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 81/150\n",
      "69701/69701 [==============================] - 5s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 82/150\n",
      "69701/69701 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 83/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 84/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 85/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 86/150\n",
      "69701/69701 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 87/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 88/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 89/150\n",
      "69701/69701 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 90/150\n",
      "69701/69701 [==============================] - 4s 55us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 91/150\n",
      "69701/69701 [==============================] - 5s 66us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 92/150\n",
      "69701/69701 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 93/150\n",
      "69701/69701 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 94/150\n",
      "69701/69701 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 95/150\n",
      "69701/69701 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 96/150\n",
      "69701/69701 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 97/150\n",
      "69701/69701 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 98/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 99/150\n",
      "69701/69701 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 100/150\n",
      "69701/69701 [==============================] - 4s 53us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 101/150\n",
      "69701/69701 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 102/150\n",
      "69701/69701 [==============================] - 4s 53us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 103/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 104/150\n",
      "69701/69701 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 105/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 106/150\n",
      "69701/69701 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 107/150\n",
      "69701/69701 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 108/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 109/150\n",
      "69701/69701 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 110/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 111/150\n",
      "69701/69701 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 112/150\n",
      "69701/69701 [==============================] - 5s 66us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 113/150\n",
      "69701/69701 [==============================] - 5s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 114/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 115/150\n",
      "69701/69701 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 116/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 117/150\n",
      "69701/69701 [==============================] - 4s 64us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 118/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 119/150\n",
      "69701/69701 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 120/150\n",
      "69701/69701 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 121/150\n",
      "69701/69701 [==============================] - 4s 63us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 122/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 123/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 124/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 125/150\n",
      "69701/69701 [==============================] - 4s 56us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69701/69701 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 127/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 128/150\n",
      "69701/69701 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 129/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 130/150\n",
      "69701/69701 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 131/150\n",
      "69701/69701 [==============================] - 5s 66us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 132/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 133/150\n",
      "69701/69701 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 134/150\n",
      "69701/69701 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 135/150\n",
      "69701/69701 [==============================] - 4s 56us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 136/150\n",
      "69701/69701 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 137/150\n",
      "69701/69701 [==============================] - 4s 59us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 138/150\n",
      "69701/69701 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 139/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 140/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 141/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 142/150\n",
      "69701/69701 [==============================] - 5s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 143/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 144/150\n",
      "69701/69701 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 145/150\n",
      "69701/69701 [==============================] - 5s 65us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 146/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 147/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 148/150\n",
      "69701/69701 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 149/150\n",
      "69701/69701 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "Epoch 150/150\n",
      "69701/69701 [==============================] - 8s 121us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269\n",
      "34850/34850 [==============================] - 3s 75us/step\n",
      "mean_squared_error: 0.19%\n",
      "Epoch 1/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0224 - mean_squared_error: 0.0224 - mean_absolute_error: 0.1125\n",
      "Epoch 2/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0044 - mean_squared_error: 0.0044 - mean_absolute_error: 0.0448\n",
      "Epoch 3/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0342\n",
      "Epoch 4/150\n",
      "69701/69701 [==============================] - 4s 62us/step - loss: 0.0026 - mean_squared_error: 0.0026 - mean_absolute_error: 0.0333\n",
      "Epoch 5/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0024 - mean_squared_error: 0.0024 - mean_absolute_error: 0.0317\n",
      "Epoch 6/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0022 - mean_squared_error: 0.0022 - mean_absolute_error: 0.0297\n",
      "Epoch 7/150\n",
      "69701/69701 [==============================] - 5s 66us/step - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0284\n",
      "Epoch 8/150\n",
      "69701/69701 [==============================] - 5s 67us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0277\n",
      "Epoch 9/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0273\n",
      "Epoch 10/150\n",
      "69701/69701 [==============================] - 4s 56us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0271\n",
      "Epoch 11/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0268\n",
      "Epoch 12/150\n",
      "69701/69701 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0265\n",
      "Epoch 13/150\n",
      "69701/69701 [==============================] - 4s 61us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0264\n",
      "Epoch 14/150\n",
      "69701/69701 [==============================] - 4s 60us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0263\n",
      "Epoch 15/150\n",
      "69701/69701 [==============================] - 4s 58us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0262\n",
      "Epoch 16/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0261\n",
      "Epoch 17/150\n",
      "69701/69701 [==============================] - 4s 57us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0261\n",
      "Epoch 18/150\n",
      "69701/69701 [==============================] - 4s 62us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0261\n",
      "Epoch 19/150\n",
      "69701/69701 [==============================] - 7s 97us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 20/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 21/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 22/150\n",
      "69701/69701 [==============================] - 7s 100us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 23/150\n",
      "69701/69701 [==============================] - 6s 93us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0260\n",
      "Epoch 24/150\n",
      "69701/69701 [==============================] - 5s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 25/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 26/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 27/150\n",
      "69701/69701 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 28/150\n",
      "69701/69701 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 29/150\n",
      "69701/69701 [==============================] - 7s 98us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 30/150\n",
      "69701/69701 [==============================] - 7s 96us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 31/150\n",
      "69701/69701 [==============================] - 7s 100us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 32/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 33/150\n",
      "69701/69701 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 34/150\n",
      "69701/69701 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 35/150\n",
      "69701/69701 [==============================] - 5s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 36/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 37/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 38/150\n",
      "69701/69701 [==============================] - 6s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 39/150\n",
      "69701/69701 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 40/150\n",
      "69701/69701 [==============================] - 6s 89us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 41/150\n",
      "69701/69701 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 42/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 43/150\n",
      "69701/69701 [==============================] - 7s 104us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 44/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 45/150\n",
      "69701/69701 [==============================] - 8s 112us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 46/150\n",
      "69701/69701 [==============================] - 7s 104us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 47/150\n",
      "69701/69701 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 48/150\n",
      "69701/69701 [==============================] - 7s 99us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 49/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 50/150\n",
      "69701/69701 [==============================] - 7s 101us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 51/150\n",
      "69701/69701 [==============================] - 8s 117us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 52/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 53/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 54/150\n",
      "69701/69701 [==============================] - 7s 104us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 55/150\n",
      "69701/69701 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 56/150\n",
      "69701/69701 [==============================] - 7s 97us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 57/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 58/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 59/150\n",
      "69701/69701 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 60/150\n",
      "69701/69701 [==============================] - 7s 105us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 61/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 62/150\n",
      "69701/69701 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 63/150\n",
      "69701/69701 [==============================] - 8s 113us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 64/150\n",
      "69701/69701 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 65/150\n",
      "69701/69701 [==============================] - 8s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 66/150\n",
      "69701/69701 [==============================] - 8s 108us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 67/150\n",
      "69701/69701 [==============================] - 9s 124us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 68/150\n",
      "69701/69701 [==============================] - 7s 101us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 69/150\n",
      "69701/69701 [==============================] - 11s 152us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 70/150\n",
      "69701/69701 [==============================] - 7s 104us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 71/150\n",
      "69701/69701 [==============================] - 8s 115us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 72/150\n",
      "69701/69701 [==============================] - 7s 101us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 73/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 74/150\n",
      "69701/69701 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 75/150\n",
      "69701/69701 [==============================] - 9s 123us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 76/150\n",
      "69701/69701 [==============================] - 8s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 77/150\n",
      "69701/69701 [==============================] - 7s 102us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 78/150\n",
      "69701/69701 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 79/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 80/150\n",
      "69701/69701 [==============================] - 6s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 81/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 82/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 83/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 84/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 85/150\n",
      "69701/69701 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 86/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 87/150\n",
      "69701/69701 [==============================] - 9s 129us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 88/150\n",
      "69701/69701 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 89/150\n",
      "69701/69701 [==============================] - 5s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 90/150\n",
      "69701/69701 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 91/150\n",
      "69701/69701 [==============================] - 9s 129us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 92/150\n",
      "69701/69701 [==============================] - 10s 143us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 93/150\n",
      "69701/69701 [==============================] - 7s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 94/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 95/150\n",
      "69701/69701 [==============================] - 5s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 96/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 97/150\n",
      "69701/69701 [==============================] - 6s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 98/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 99/150\n",
      "69701/69701 [==============================] - 6s 88us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 100/150\n",
      "69701/69701 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 101/150\n",
      "69701/69701 [==============================] - 6s 92us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 102/150\n",
      "69701/69701 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 103/150\n",
      "69701/69701 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 104/150\n",
      "69701/69701 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 105/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0258\n",
      "Epoch 106/150\n",
      "69701/69701 [==============================] - 6s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 107/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 108/150\n",
      "69701/69701 [==============================] - 6s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 109/150\n",
      "69701/69701 [==============================] - 9s 131us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 110/150\n",
      "69701/69701 [==============================] - 10s 143us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 111/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 112/150\n",
      "69701/69701 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 113/150\n",
      "69701/69701 [==============================] - 7s 106us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 114/150\n",
      "69701/69701 [==============================] - 7s 107us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 115/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 116/150\n",
      "69701/69701 [==============================] - 6s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 117/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 118/150\n",
      "69701/69701 [==============================] - 7s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 119/150\n",
      "69701/69701 [==============================] - 8s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 120/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 121/150\n",
      "69701/69701 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 122/150\n",
      "69701/69701 [==============================] - 6s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 123/150\n",
      "69701/69701 [==============================] - 10s 137us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 124/150\n",
      "69701/69701 [==============================] - 6s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 125/150\n",
      "69701/69701 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 126/150\n",
      "69701/69701 [==============================] - 6s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 127/150\n",
      "69701/69701 [==============================] - 7s 105us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 128/150\n",
      "69701/69701 [==============================] - 9s 131us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 129/150\n",
      "69701/69701 [==============================] - 11s 152us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 130/150\n",
      "69701/69701 [==============================] - 10s 140us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 131/150\n",
      "69701/69701 [==============================] - 9s 126us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 132/150\n",
      "69701/69701 [==============================] - 8s 119us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 133/150\n",
      "69701/69701 [==============================] - 12s 174us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 134/150\n",
      "69701/69701 [==============================] - 14s 207us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 135/150\n",
      "69701/69701 [==============================] - 14s 198us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 136/150\n",
      "69701/69701 [==============================] - 13s 180us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 137/150\n",
      "69701/69701 [==============================] - 14s 202us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 138/150\n",
      "69701/69701 [==============================] - 12s 171us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 139/150\n",
      "69701/69701 [==============================] - 11s 159us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 140/150\n",
      "69701/69701 [==============================] - 12s 170us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 141/150\n",
      "69701/69701 [==============================] - 10s 142us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 142/150\n",
      "69701/69701 [==============================] - 11s 153us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 143/150\n",
      "69701/69701 [==============================] - 13s 179us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 144/150\n",
      "69701/69701 [==============================] - 12s 177us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 145/150\n",
      "69701/69701 [==============================] - 11s 158us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 146/150\n",
      "69701/69701 [==============================] - 14s 194us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 147/150\n",
      "69701/69701 [==============================] - 13s 192us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 148/150\n",
      "69701/69701 [==============================] - 10s 142us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 149/150\n",
      "69701/69701 [==============================] - 13s 189us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "Epoch 150/150\n",
      "69701/69701 [==============================] - 11s 158us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0259\n",
      "34850/34850 [==============================] - 5s 139us/step\n",
      "mean_squared_error: 0.19%\n",
      "0.19% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# kfold cross validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "kfold = KFold(n_splits=3)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(xscale):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(len(y[0]), activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "    model.fit(xscale[train], yscale[train], epochs=150, batch_size=50)\n",
    "    scores = model.evaluate(xscale[test], yscale[test])\n",
    "    print('%s: %.2f%%' %(model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print('%.2f%% (+/- %.2f%%)' %(np.mean(cvscores), np.std(cvscores)))\n",
    "model_dict[np.mean(cvscores)] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 12)                36        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 61)                305       \n",
      "=================================================================\n",
      "Total params: 413\n",
      "Trainable params: 413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(len(y[0]), activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62730 samples, validate on 15683 samples\n",
      "Epoch 1/200\n",
      "62730/62730 [==============================] - 6s 93us/step - loss: 0.0153 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0841 - val_loss: 0.0033 - val_mean_squared_error: 0.0033 - val_mean_absolute_error: 0.0405\n",
      "Epoch 2/200\n",
      "62730/62730 [==============================] - 6s 90us/step - loss: 0.0029 - mean_squared_error: 0.0029 - mean_absolute_error: 0.0370 - val_loss: 0.0028 - val_mean_squared_error: 0.0028 - val_mean_absolute_error: 0.0353\n",
      "Epoch 3/200\n",
      "62730/62730 [==============================] - 8s 130us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0347 - val_loss: 0.0027 - val_mean_squared_error: 0.0027 - val_mean_absolute_error: 0.0340\n",
      "Epoch 4/200\n",
      "62730/62730 [==============================] - 6s 102us/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0339 - val_loss: 0.0026 - val_mean_squared_error: 0.0026 - val_mean_absolute_error: 0.0333\n",
      "Epoch 5/200\n",
      "62730/62730 [==============================] - 5s 80us/step - loss: 0.0025 - mean_squared_error: 0.0025 - mean_absolute_error: 0.0326 - val_loss: 0.0024 - val_mean_squared_error: 0.0024 - val_mean_absolute_error: 0.0317\n",
      "Epoch 6/200\n",
      "62730/62730 [==============================] - 6s 100us/step - loss: 0.0023 - mean_squared_error: 0.0023 - mean_absolute_error: 0.0306 - val_loss: 0.0022 - val_mean_squared_error: 0.0022 - val_mean_absolute_error: 0.0295\n",
      "Epoch 7/200\n",
      "62730/62730 [==============================] - 7s 104us/step - loss: 0.0021 - mean_squared_error: 0.0021 - mean_absolute_error: 0.0290 - val_loss: 0.0021 - val_mean_squared_error: 0.0021 - val_mean_absolute_error: 0.0282\n",
      "Epoch 8/200\n",
      "62730/62730 [==============================] - 6s 98us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0280 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0276\n",
      "Epoch 9/200\n",
      "62730/62730 [==============================] - 6s 89us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0275 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0272\n",
      "Epoch 10/200\n",
      "62730/62730 [==============================] - 5s 85us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0272 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0269\n",
      "Epoch 11/200\n",
      "62730/62730 [==============================] - 7s 112us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0271 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 12/200\n",
      "62730/62730 [==============================] - 7s 104us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 13/200\n",
      "62730/62730 [==============================] - 7s 106us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 14/200\n",
      "62730/62730 [==============================] - 9s 139us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0271\n",
      "Epoch 15/200\n",
      "62730/62730 [==============================] - 6s 99us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 16/200\n",
      "62730/62730 [==============================] - 10s 157us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0273\n",
      "Epoch 17/200\n",
      "62730/62730 [==============================] - 7s 108us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 18/200\n",
      "62730/62730 [==============================] - 8s 126us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 19/200\n",
      "62730/62730 [==============================] - 9s 149us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 20/200\n",
      "62730/62730 [==============================] - 7s 114us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 21/200\n",
      "62730/62730 [==============================] - 6s 102us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 22/200\n",
      "62730/62730 [==============================] - 7s 110us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 23/200\n",
      "62730/62730 [==============================] - 7s 113us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 24/200\n",
      "62730/62730 [==============================] - 10s 156us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 25/200\n",
      "62730/62730 [==============================] - 7s 105us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 26/200\n",
      "62730/62730 [==============================] - 8s 125us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 27/200\n",
      "62730/62730 [==============================] - 6s 91us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 28/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0274\n",
      "Epoch 29/200\n",
      "62730/62730 [==============================] - 5s 82us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 30/200\n",
      "62730/62730 [==============================] - 6s 98us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 31/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 32/200\n",
      "62730/62730 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 33/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 34/200\n",
      "62730/62730 [==============================] - 6s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 35/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 37/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 38/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 39/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 40/200\n",
      "62730/62730 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 41/200\n",
      "62730/62730 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 42/200\n",
      "62730/62730 [==============================] - 4s 71us/step - loss: 0.0020 - mean_squared_error: 0.0020 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 43/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 44/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 45/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0271\n",
      "Epoch 46/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 47/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 48/200\n",
      "62730/62730 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 49/200\n",
      "62730/62730 [==============================] - 4s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 50/200\n",
      "62730/62730 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 51/200\n",
      "62730/62730 [==============================] - 4s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 52/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 53/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 54/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 55/200\n",
      "62730/62730 [==============================] - 4s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 56/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 57/200\n",
      "62730/62730 [==============================] - 4s 67us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 58/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 59/200\n",
      "62730/62730 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 60/200\n",
      "62730/62730 [==============================] - 4s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 61/200\n",
      "62730/62730 [==============================] - 5s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 62/200\n",
      "62730/62730 [==============================] - 6s 90us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 63/200\n",
      "62730/62730 [==============================] - 5s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 64/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0272\n",
      "Epoch 65/200\n",
      "62730/62730 [==============================] - 4s 68us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 66/200\n",
      "62730/62730 [==============================] - 4s 71us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 67/200\n",
      "62730/62730 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 68/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 69/200\n",
      "62730/62730 [==============================] - 5s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 70/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 71/200\n",
      "62730/62730 [==============================] - 6s 89us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 72/200\n",
      "62730/62730 [==============================] - 6s 95us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 73/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 74/200\n",
      "62730/62730 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 75/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 76/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 77/200\n",
      "62730/62730 [==============================] - 4s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 78/200\n",
      "62730/62730 [==============================] - 5s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 79/200\n",
      "62730/62730 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 80/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0274\n",
      "Epoch 81/200\n",
      "62730/62730 [==============================] - 4s 69us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 82/200\n",
      "62730/62730 [==============================] - 4s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 83/200\n",
      "62730/62730 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 84/200\n",
      "62730/62730 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 85/200\n",
      "62730/62730 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 86/200\n",
      "62730/62730 [==============================] - 5s 73us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0271\n",
      "Epoch 87/200\n",
      "62730/62730 [==============================] - 5s 72us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 88/200\n",
      "62730/62730 [==============================] - 5s 74us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0271\n",
      "Epoch 89/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 90/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 91/200\n",
      "62730/62730 [==============================] - 5s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 92/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 93/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 94/200\n",
      "62730/62730 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 95/200\n",
      "62730/62730 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 96/200\n",
      "62730/62730 [==============================] - 5s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 97/200\n",
      "62730/62730 [==============================] - 5s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 98/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 99/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 100/200\n",
      "62730/62730 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 101/200\n",
      "62730/62730 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 102/200\n",
      "62730/62730 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 103/200\n",
      "62730/62730 [==============================] - 5s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0269\n",
      "Epoch 104/200\n",
      "62730/62730 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 105/200\n",
      "62730/62730 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62730/62730 [==============================] - 5s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 107/200\n",
      "62730/62730 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 108/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 109/200\n",
      "62730/62730 [==============================] - 4s 70us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 110/200\n",
      "62730/62730 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 111/200\n",
      "62730/62730 [==============================] - 5s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 112/200\n",
      "62730/62730 [==============================] - 5s 80us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 113/200\n",
      "62730/62730 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 114/200\n",
      "62730/62730 [==============================] - 5s 77us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 115/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 116/200\n",
      "62730/62730 [==============================] - 5s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 117/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 118/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0020 - val_mean_squared_error: 0.0020 - val_mean_absolute_error: 0.0271\n",
      "Epoch 119/200\n",
      "62730/62730 [==============================] - 5s 82us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 120/200\n",
      "62730/62730 [==============================] - 5s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0270 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 121/200\n",
      "62730/62730 [==============================] - 5s 76us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 122/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 123/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 124/200\n",
      "62730/62730 [==============================] - 5s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 125/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 126/200\n",
      "62730/62730 [==============================] - 5s 86us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 127/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 128/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 129/200\n",
      "62730/62730 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 130/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 131/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 132/200\n",
      "62730/62730 [==============================] - 5s 75us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 133/200\n",
      "62730/62730 [==============================] - 5s 78us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0270\n",
      "Epoch 134/200\n",
      "62730/62730 [==============================] - 5s 79us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 135/200\n",
      "62730/62730 [==============================] - 5s 85us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 136/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0271\n",
      "Epoch 137/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 138/200\n",
      "62730/62730 [==============================] - 5s 84us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 139/200\n",
      "62730/62730 [==============================] - 5s 87us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0267\n",
      "Epoch 140/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0269\n",
      "Epoch 141/200\n",
      "62730/62730 [==============================] - 5s 83us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 142/200\n",
      "62730/62730 [==============================] - 5s 81us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 143/200\n",
      "62730/62730 [==============================] - 6s 94us/step - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0269 - val_loss: 0.0019 - val_mean_squared_error: 0.0019 - val_mean_absolute_error: 0.0268\n",
      "Epoch 144/200\n",
      "22800/62730 [=========>....................] - ETA: 2s - loss: 0.0019 - mean_squared_error: 0.0019 - mean_absolute_error: 0.0268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-c07a8e30f20f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(xtrain, ytrain, epochs=200, batch_size=50, validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history.keys())\n",
    "plt.semilogy(hist.history['loss'])\n",
    "plt.semilogy(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_bu = np.array([[3.3, 43872]])\n",
    "\n",
    "xnew = xscaler.transform(enr_bu)\n",
    "all_dat['err'] = abs(all_dat['bu'] - enr_bu[0][1]) + abs(all_dat['init_enr'] - enr_bu[0][0]) * 1e4\n",
    "min_err = all_dat['err'].idxmin()\n",
    "all_dat = all_dat.drop(columns='err')\n",
    "avg_assem = all_dat.loc[min_err]\n",
    "print('UDB assembly enr bu: ', [avg_assem['init_enr'], avg_assem['bu']])\n",
    "\n",
    "ynew = yscaler.inverse_transform(model.predict(xnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Isotope \\t Predicted \\t Data \\t %Error')\n",
    "tot_err = 0\n",
    "for indx, i in enumerate(iso_list):\n",
    "    err = ynew[0][indx] - avg_assem[i]\n",
    "    percent_err = err / avg_assem[i] * 100\n",
    "    tot_err += err\n",
    "    print(i, '\\t', ynew[0][indx], '\\t', avg_assem[i], '\\t', percent_err)\n",
    "\n",
    "print('\\n', tot_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "model_dict[tot_err] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c3594b89377f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \"\"\"\n\u001b[1;32m    333\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "model.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "/home/teddy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (60,) but got array with shape (62,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c55a0dc798ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0muse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps_per_epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m         validation_split=validation_split)\n\u001b[0m\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,\n\u001b[0;32m--> 992\u001b[0;31m                                                      class_weight, batch_size)\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_weights\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   1152\u001b[0m           \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m           exception_prefix='target')\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (60,) but got array with shape (62,)"
     ]
    }
   ],
   "source": [
    "# grid search to find best hyperparameter\n",
    "\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0,\n",
    "                 activation='relu', neurons=1,\n",
    "                 hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=2, activation=activation))\n",
    "    # consider putting in dropout?\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(60, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_percentage_error'])\n",
    "    return model\n",
    "\n",
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,4:]\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "param_grid = dict(batch_size=[10, 20, 40, 60, 80],\n",
    "                  epochs=[10, 50, 100, 200],\n",
    "                  optimizer=['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "                  # learn rate and momentum implementation???\n",
    "                  activation = ['relu', 'softmax', 'softplus', 'softsign', 'tanh', 'linear'],\n",
    "                  neurons = [1, 5, 10, 20, 40, 80],\n",
    "                  hidden_layers = [0, 1, 3, 5, 10]\n",
    "                  )\n",
    "result_dict = {}\n",
    "\n",
    "# for every hyperparameter, run a grid search\n",
    "for param, param_list in param_grid.items():\n",
    "    print(param, '\\n\\n')\n",
    "    use = {param: param_list}\n",
    "    grid = GridSearchCV(estimator=model, param_grid=use)\n",
    "    grid_result = grid.fit(x, y)\n",
    "    result_dict[param] = (grid_result.best_score_, grid_result.best_params_)\n",
    "    # summarize results\n",
    "    print('Best: %f using %s' %(grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    #for mean, stdev. param in zip(means, stds, params):\n",
    "    #    print('%f (%f) with: %r' %(mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': (-37339.71153245486, {'batch_size': 20}),\n",
       " 'epochs': (-26118.439008011042, {'epochs': 100}),\n",
       " 'optimizer': (-64947.83971664397, {'optimizer': 'Adamax'}),\n",
       " 'activation': (-54298.19828140842, {'activation': 'softsign'}),\n",
       " 'neurons': (-72339.40957284004, {'neurons': 1}),\n",
       " 'hidden_layers': (-28876.054231980685, {'hidden_layers': 10})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x7f0e9c2dd710>\n",
      "Train on 73185 samples, validate on 31366 samples\n",
      "Epoch 1/100\n",
      "73185/73185 [==============================] - 24s 334us/step - loss: 88177.8860 - mean_absolute_percentage_error: 88177.8860 - val_loss: 76297.6464 - val_mean_absolute_percentage_error: 76297.6464\n",
      "Epoch 2/100\n",
      "73185/73185 [==============================] - 18s 243us/step - loss: 71776.8624 - mean_absolute_percentage_error: 71776.8624 - val_loss: 66387.5748 - val_mean_absolute_percentage_error: 66387.5748\n",
      "Epoch 3/100\n",
      "73185/73185 [==============================] - 17s 227us/step - loss: 71383.8011 - mean_absolute_percentage_error: 71383.8011 - val_loss: 86997.0727 - val_mean_absolute_percentage_error: 86997.0727\n",
      "Epoch 4/100\n",
      "73185/73185 [==============================] - 16s 218us/step - loss: 72922.7693 - mean_absolute_percentage_error: 72922.7693 - val_loss: 66281.3289 - val_mean_absolute_percentage_error: 66281.3289\n",
      "Epoch 5/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 75174.1389 - mean_absolute_percentage_error: 75174.1389 - val_loss: 66275.5601 - val_mean_absolute_percentage_error: 66275.5601\n",
      "Epoch 6/100\n",
      "73185/73185 [==============================] - 16s 219us/step - loss: 73798.0947 - mean_absolute_percentage_error: 73798.0947 - val_loss: 73138.0659 - val_mean_absolute_percentage_error: 73138.0659\n",
      "Epoch 7/100\n",
      "73185/73185 [==============================] - 16s 218us/step - loss: 76586.4221 - mean_absolute_percentage_error: 76586.4221 - val_loss: 77035.5503 - val_mean_absolute_percentage_error: 77035.5503\n",
      "Epoch 8/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 75758.8037 - mean_absolute_percentage_error: 75758.8037 - val_loss: 83912.7832 - val_mean_absolute_percentage_error: 83912.7832\n",
      "Epoch 9/100\n",
      "73185/73185 [==============================] - 16s 219us/step - loss: 74695.9809 - mean_absolute_percentage_error: 74695.9809 - val_loss: 101447.4250 - val_mean_absolute_percentage_error: 101447.4250\n",
      "Epoch 10/100\n",
      "73185/73185 [==============================] - 17s 227us/step - loss: 73134.1447 - mean_absolute_percentage_error: 73134.1447 - val_loss: 77709.2228 - val_mean_absolute_percentage_error: 77709.2228\n",
      "Epoch 11/100\n",
      "73185/73185 [==============================] - 16s 217us/step - loss: 72889.9083 - mean_absolute_percentage_error: 72889.9083 - val_loss: 47298.8597 - val_mean_absolute_percentage_error: 47298.8597\n",
      "Epoch 12/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 69257.1391 - mean_absolute_percentage_error: 69257.1391 - val_loss: 74673.0227 - val_mean_absolute_percentage_error: 74673.0227\n",
      "Epoch 13/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70208.5364 - mean_absolute_percentage_error: 70208.5364 - val_loss: 72030.7407 - val_mean_absolute_percentage_error: 72030.7407\n",
      "Epoch 14/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70284.2412 - mean_absolute_percentage_error: 70284.2412 - val_loss: 75813.1071 - val_mean_absolute_percentage_error: 75813.1071\n",
      "Epoch 15/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71803.3386 - mean_absolute_percentage_error: 71803.3386 - val_loss: 92599.2900 - val_mean_absolute_percentage_error: 92599.2900\n",
      "Epoch 16/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 74179.7592 - mean_absolute_percentage_error: 74179.7592 - val_loss: 83694.9755 - val_mean_absolute_percentage_error: 83694.9755\n",
      "Epoch 17/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 73951.6685 - mean_absolute_percentage_error: 73951.6685 - val_loss: 87476.2474 - val_mean_absolute_percentage_error: 87476.2474\n",
      "Epoch 18/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 70901.6441 - mean_absolute_percentage_error: 70901.6441 - val_loss: 76895.3145 - val_mean_absolute_percentage_error: 76895.3145\n",
      "Epoch 19/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71297.1570 - mean_absolute_percentage_error: 71297.1570 - val_loss: 76300.2229 - val_mean_absolute_percentage_error: 76300.2229\n",
      "Epoch 20/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71703.4390 - mean_absolute_percentage_error: 71703.4390 - val_loss: 70406.9166 - val_mean_absolute_percentage_error: 70406.9166\n",
      "Epoch 21/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73554.1439 - mean_absolute_percentage_error: 73554.1439 - val_loss: 79254.5046 - val_mean_absolute_percentage_error: 79254.5046\n",
      "Epoch 22/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72640.0529 - mean_absolute_percentage_error: 72640.0529 - val_loss: 80725.0438 - val_mean_absolute_percentage_error: 80725.0438\n",
      "Epoch 23/100\n",
      "73185/73185 [==============================] - 16s 215us/step - loss: 70316.3832 - mean_absolute_percentage_error: 70316.3832 - val_loss: 68550.6065 - val_mean_absolute_percentage_error: 68550.6065\n",
      "Epoch 24/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71506.9705 - mean_absolute_percentage_error: 71506.9705 - val_loss: 61941.9341 - val_mean_absolute_percentage_error: 61941.9341\n",
      "Epoch 25/100\n",
      "73185/73185 [==============================] - 16s 216us/step - loss: 72851.8786 - mean_absolute_percentage_error: 72851.8786 - val_loss: 82948.3677 - val_mean_absolute_percentage_error: 82948.3677\n",
      "Epoch 26/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72968.4548 - mean_absolute_percentage_error: 72968.4548 - val_loss: 80020.2702 - val_mean_absolute_percentage_error: 80020.2702\n",
      "Epoch 27/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72850.2824 - mean_absolute_percentage_error: 72850.2824 - val_loss: 75912.4180 - val_mean_absolute_percentage_error: 75912.4180\n",
      "Epoch 28/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73371.3635 - mean_absolute_percentage_error: 73371.3635 - val_loss: 67047.2809 - val_mean_absolute_percentage_error: 67047.2809\n",
      "Epoch 29/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 75547.5171 - mean_absolute_percentage_error: 75547.5171 - val_loss: 83583.9931 - val_mean_absolute_percentage_error: 83583.9931\n",
      "Epoch 30/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74239.4051 - mean_absolute_percentage_error: 74239.4051 - val_loss: 68528.3354 - val_mean_absolute_percentage_error: 68528.3354\n",
      "Epoch 31/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 71355.5589 - mean_absolute_percentage_error: 71355.5589 - val_loss: 60007.3089 - val_mean_absolute_percentage_error: 60007.3089\n",
      "Epoch 32/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72528.3649 - mean_absolute_percentage_error: 72528.3649 - val_loss: 86829.5471 - val_mean_absolute_percentage_error: 86829.5471\n",
      "Epoch 33/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72466.2313 - mean_absolute_percentage_error: 72466.2313 - val_loss: 87147.3809 - val_mean_absolute_percentage_error: 87147.3809\n",
      "Epoch 34/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71738.2817 - mean_absolute_percentage_error: 71738.2817 - val_loss: 62230.3339 - val_mean_absolute_percentage_error: 62230.3339\n",
      "Epoch 35/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 73849.2161 - mean_absolute_percentage_error: 73849.2161 - val_loss: 76137.6067 - val_mean_absolute_percentage_error: 76137.6067\n",
      "Epoch 36/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69923.9724 - mean_absolute_percentage_error: 69923.9724 - val_loss: 84789.3068 - val_mean_absolute_percentage_error: 84789.3068\n",
      "Epoch 37/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68236.4944 - mean_absolute_percentage_error: 68236.4944 - val_loss: 59130.9267 - val_mean_absolute_percentage_error: 59130.9267\n",
      "Epoch 38/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68196.5417 - mean_absolute_percentage_error: 68196.5417 - val_loss: 60015.2813 - val_mean_absolute_percentage_error: 60015.2813\n",
      "Epoch 39/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68745.6717 - mean_absolute_percentage_error: 68745.6717 - val_loss: 100072.1471 - val_mean_absolute_percentage_error: 100072.1471\n",
      "Epoch 40/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 68765.0778 - mean_absolute_percentage_error: 68765.0778 - val_loss: 71391.0159 - val_mean_absolute_percentage_error: 71391.0159\n",
      "Epoch 41/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69671.2282 - mean_absolute_percentage_error: 69671.2282 - val_loss: 72415.5808 - val_mean_absolute_percentage_error: 72415.5808\n",
      "Epoch 42/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 69786.3615 - mean_absolute_percentage_error: 69786.3615 - val_loss: 81661.7223 - val_mean_absolute_percentage_error: 81661.7223\n",
      "Epoch 43/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71513.1146 - mean_absolute_percentage_error: 71513.1146 - val_loss: 70954.3089 - val_mean_absolute_percentage_error: 70954.3089\n",
      "Epoch 44/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70578.9827 - mean_absolute_percentage_error: 70578.9827 - val_loss: 83601.1950 - val_mean_absolute_percentage_error: 83601.1950\n",
      "Epoch 45/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71412.6494 - mean_absolute_percentage_error: 71412.6494 - val_loss: 93161.5678 - val_mean_absolute_percentage_error: 93161.5678\n",
      "Epoch 46/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71017.8248 - mean_absolute_percentage_error: 71017.8248 - val_loss: 78061.4125 - val_mean_absolute_percentage_error: 78061.4125\n",
      "Epoch 47/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71695.7787 - mean_absolute_percentage_error: 71695.7787 - val_loss: 95129.0020 - val_mean_absolute_percentage_error: 95129.0020\n",
      "Epoch 48/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72262.0495 - mean_absolute_percentage_error: 72262.0495 - val_loss: 82658.0063 - val_mean_absolute_percentage_error: 82658.0063\n",
      "Epoch 49/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73170.1839 - mean_absolute_percentage_error: 73170.1839 - val_loss: 62144.9654 - val_mean_absolute_percentage_error: 62144.9654\n",
      "Epoch 50/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 72412.2551 - mean_absolute_percentage_error: 72412.2551 - val_loss: 78507.2766 - val_mean_absolute_percentage_error: 78507.2766\n",
      "Epoch 51/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71455.0052 - mean_absolute_percentage_error: 71455.0052 - val_loss: 83298.1384 - val_mean_absolute_percentage_error: 83298.1384\n",
      "Epoch 52/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72617.8439 - mean_absolute_percentage_error: 72617.8439 - val_loss: 56917.1428 - val_mean_absolute_percentage_error: 56917.1428\n",
      "Epoch 53/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 73113.9897 - mean_absolute_percentage_error: 73113.9897 - val_loss: 71171.4638 - val_mean_absolute_percentage_error: 71171.4638\n",
      "Epoch 54/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 72640.1208 - mean_absolute_percentage_error: 72640.1208 - val_loss: 63341.6959 - val_mean_absolute_percentage_error: 63341.6959\n",
      "Epoch 55/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74744.5418 - mean_absolute_percentage_error: 74744.5418 - val_loss: 61852.4458 - val_mean_absolute_percentage_error: 61852.4458\n",
      "Epoch 56/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73006.9006 - mean_absolute_percentage_error: 73006.9006 - val_loss: 84960.1659 - val_mean_absolute_percentage_error: 84960.1659\n",
      "Epoch 57/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 73384.8217 - mean_absolute_percentage_error: 73384.8217 - val_loss: 57499.4290 - val_mean_absolute_percentage_error: 57499.4290\n",
      "Epoch 58/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 70959.5627 - mean_absolute_percentage_error: 70959.5627 - val_loss: 74756.7736 - val_mean_absolute_percentage_error: 74756.7736\n",
      "Epoch 59/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 74050.7578 - mean_absolute_percentage_error: 74050.7578 - val_loss: 83979.7247 - val_mean_absolute_percentage_error: 83979.7247\n",
      "Epoch 60/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 73595.4047 - mean_absolute_percentage_error: 73595.4047 - val_loss: 65352.4208 - val_mean_absolute_percentage_error: 65352.4208\n",
      "Epoch 61/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73932.6425 - mean_absolute_percentage_error: 73932.6425 - val_loss: 67093.5760 - val_mean_absolute_percentage_error: 67093.5760\n",
      "Epoch 62/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 73824.9415 - mean_absolute_percentage_error: 73824.9415 - val_loss: 97635.1258 - val_mean_absolute_percentage_error: 97635.1258\n",
      "Epoch 63/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 73238.7050 - mean_absolute_percentage_error: 73238.7050 - val_loss: 66329.3939 - val_mean_absolute_percentage_error: 66329.3939\n",
      "Epoch 64/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 71972.0366 - mean_absolute_percentage_error: 71972.0366 - val_loss: 51382.6440 - val_mean_absolute_percentage_error: 51382.6440\n",
      "Epoch 65/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 68715.4248 - mean_absolute_percentage_error: 68715.4248 - val_loss: 83887.5295 - val_mean_absolute_percentage_error: 83887.5295\n",
      "Epoch 66/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69422.0180 - mean_absolute_percentage_error: 69422.0180 - val_loss: 70328.8957 - val_mean_absolute_percentage_error: 70328.8957\n",
      "Epoch 67/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70268.2656 - mean_absolute_percentage_error: 70268.2656 - val_loss: 85864.2286 - val_mean_absolute_percentage_error: 85864.2286\n",
      "Epoch 68/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69692.0971 - mean_absolute_percentage_error: 69692.0971 - val_loss: 63615.2444 - val_mean_absolute_percentage_error: 63615.2444\n",
      "Epoch 69/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 71240.0152 - mean_absolute_percentage_error: 71240.0152 - val_loss: 82727.7221 - val_mean_absolute_percentage_error: 82727.7221\n",
      "Epoch 70/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70035.1911 - mean_absolute_percentage_error: 70035.1911 - val_loss: 71092.8966 - val_mean_absolute_percentage_error: 71092.8966\n",
      "Epoch 71/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71171.0975 - mean_absolute_percentage_error: 71171.0975 - val_loss: 60215.3691 - val_mean_absolute_percentage_error: 60215.3691\n",
      "Epoch 72/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70054.0061 - mean_absolute_percentage_error: 70054.0061 - val_loss: 84827.7476 - val_mean_absolute_percentage_error: 84827.7476\n",
      "Epoch 73/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70402.0413 - mean_absolute_percentage_error: 70402.0413 - val_loss: 67860.1209 - val_mean_absolute_percentage_error: 67860.1209\n",
      "Epoch 74/100\n",
      "73185/73185 [==============================] - 15s 199us/step - loss: 70098.3934 - mean_absolute_percentage_error: 70098.3934 - val_loss: 74515.4638 - val_mean_absolute_percentage_error: 74515.4638\n",
      "Epoch 75/100\n",
      "73185/73185 [==============================] - 15s 203us/step - loss: 70723.3444 - mean_absolute_percentage_error: 70723.3444 - val_loss: 56020.7061 - val_mean_absolute_percentage_error: 56020.7061\n",
      "Epoch 76/100\n",
      "73185/73185 [==============================] - 15s 205us/step - loss: 70949.9630 - mean_absolute_percentage_error: 70949.9630 - val_loss: 69787.9597 - val_mean_absolute_percentage_error: 69787.9597\n",
      "Epoch 77/100\n",
      "73185/73185 [==============================] - 14s 191us/step - loss: 70664.9296 - mean_absolute_percentage_error: 70664.9296 - val_loss: 83353.5864 - val_mean_absolute_percentage_error: 83353.5864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "73185/73185 [==============================] - 15s 208us/step - loss: 70375.6989 - mean_absolute_percentage_error: 70375.6989 - val_loss: 74180.0553 - val_mean_absolute_percentage_error: 74180.0553\n",
      "Epoch 79/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70814.4295 - mean_absolute_percentage_error: 70814.4295 - val_loss: 85027.3690 - val_mean_absolute_percentage_error: 85027.3690\n",
      "Epoch 80/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70454.8263 - mean_absolute_percentage_error: 70454.8263 - val_loss: 86863.8476 - val_mean_absolute_percentage_error: 86863.8476\n",
      "Epoch 81/100\n",
      "73185/73185 [==============================] - 15s 210us/step - loss: 70866.0745 - mean_absolute_percentage_error: 70866.0745 - val_loss: 90682.0947 - val_mean_absolute_percentage_error: 90682.0947\n",
      "Epoch 82/100\n",
      "73185/73185 [==============================] - 15s 210us/step - loss: 69912.6575 - mean_absolute_percentage_error: 69912.6575 - val_loss: 52640.3338 - val_mean_absolute_percentage_error: 52640.3338\n",
      "Epoch 83/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70539.1420 - mean_absolute_percentage_error: 70539.1420 - val_loss: 73446.2364 - val_mean_absolute_percentage_error: 73446.2364\n",
      "Epoch 84/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69792.7883 - mean_absolute_percentage_error: 69792.7883 - val_loss: 70524.7690 - val_mean_absolute_percentage_error: 70524.7690\n",
      "Epoch 85/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 68409.2679 - mean_absolute_percentage_error: 68409.2679 - val_loss: 71899.2593 - val_mean_absolute_percentage_error: 71899.2593\n",
      "Epoch 86/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70721.7637 - mean_absolute_percentage_error: 70721.7637 - val_loss: 71310.7056 - val_mean_absolute_percentage_error: 71310.7056\n",
      "Epoch 87/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 70228.1081 - mean_absolute_percentage_error: 70228.1081 - val_loss: 72461.8812 - val_mean_absolute_percentage_error: 72461.8812\n",
      "Epoch 88/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 68600.9001 - mean_absolute_percentage_error: 68600.9001 - val_loss: 75261.6803 - val_mean_absolute_percentage_error: 75261.6803\n",
      "Epoch 89/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70094.5149 - mean_absolute_percentage_error: 70094.5149 - val_loss: 61978.9363 - val_mean_absolute_percentage_error: 61978.9363\n",
      "Epoch 90/100\n",
      "73185/73185 [==============================] - 15s 212us/step - loss: 68293.3034 - mean_absolute_percentage_error: 68293.3034 - val_loss: 52865.1689 - val_mean_absolute_percentage_error: 52865.1689\n",
      "Epoch 91/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 66767.7737 - mean_absolute_percentage_error: 66767.7737 - val_loss: 79177.7573 - val_mean_absolute_percentage_error: 79177.7573\n",
      "Epoch 92/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 70571.6620 - mean_absolute_percentage_error: 70571.6620 - val_loss: 94018.4021 - val_mean_absolute_percentage_error: 94018.4021\n",
      "Epoch 93/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 69951.4603 - mean_absolute_percentage_error: 69951.4603 - val_loss: 57747.0817 - val_mean_absolute_percentage_error: 57747.0817\n",
      "Epoch 94/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70345.4998 - mean_absolute_percentage_error: 70345.4998 - val_loss: 64859.2549 - val_mean_absolute_percentage_error: 64859.2549\n",
      "Epoch 95/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 70635.7272 - mean_absolute_percentage_error: 70635.7272 - val_loss: 90067.0441 - val_mean_absolute_percentage_error: 90067.0441\n",
      "Epoch 96/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69202.2595 - mean_absolute_percentage_error: 69202.2595 - val_loss: 63398.4961 - val_mean_absolute_percentage_error: 63398.4961\n",
      "Epoch 97/100\n",
      "73185/73185 [==============================] - 16s 212us/step - loss: 69016.9767 - mean_absolute_percentage_error: 69016.9767 - val_loss: 72729.9435 - val_mean_absolute_percentage_error: 72729.9435\n",
      "Epoch 98/100\n",
      "73185/73185 [==============================] - 16s 213us/step - loss: 71753.9803 - mean_absolute_percentage_error: 71753.9803 - val_loss: 66843.0989 - val_mean_absolute_percentage_error: 66843.0989\n",
      "Epoch 99/100\n",
      "73185/73185 [==============================] - 16s 214us/step - loss: 72365.2606 - mean_absolute_percentage_error: 72365.2606 - val_loss: 101087.6113 - val_mean_absolute_percentage_error: 101087.6113\n",
      "Epoch 100/100\n",
      "73185/73185 [==============================] - 15s 211us/step - loss: 72426.1962 - mean_absolute_percentage_error: 72426.1962 - val_loss: 81406.2984 - val_mean_absolute_percentage_error: 81406.2984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Sequential.evaluate of <keras.models.Sequential object at 0x7f0e9c2dd710>>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the best:\n",
    "def get_val(dictionary, key):\n",
    "    return dictionary[key][1][key]\n",
    "batch_size = get_val(result_dict, 'batch_size')\n",
    "epochs = get_val(result_dict, 'epochs')\n",
    "optimizer = get_val(result_dict, 'optimizer')\n",
    "activation = get_val(result_dict, 'activation')\n",
    "neurons = get_val(result_dict, 'neurons')\n",
    "hidden_layer = get_val(result_dict, 'hidden_layers')\n",
    "def create_model(optimizer='adam', learn_rate=0.01, momentum=0,\n",
    "                 activation='relu', neurons=1,\n",
    "                 hidden_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=2, activation=activation))\n",
    "    # consider putting in dropout?\n",
    "    for i in range(hidden_layers):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(60, activation='linear'))\n",
    "    model.compile(loss='mean_absolute_percentage_error', optimizer=optimizer,\n",
    "                  metrics=['mean_absolute_percentage_error'])\n",
    "    return model\n",
    "\n",
    "x = all_dat[['init_enr', 'bu']].as_matrix()\n",
    "y = all_dat.iloc[:,4:]\n",
    "\n",
    "model =  create_model(optimizer=optimizer, activation=activation, neurons=neurons,\n",
    "                     hidden_layers=hidden_layer)\n",
    "print(model)\n",
    "model.fit(x, y, epochs=epochs, batch_size=batch_size, validation_split=0.3)\n",
    "model.evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = x[300]\n",
    "prediction = model.predict(x)\n",
    "iso_list = list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "\n",
    "for indx, val in enumerate(prediction[300]):\n",
    "    err.append((val-np.array(y.iloc[300])[indx]) / np.array(y.iloc[300])[indx])\n",
    "    print(iso_list[indx], '\\t\\t', val, '\\t\\t', np.array(y.iloc[300])[indx])\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "    \n",
    "for indx, val in enumerate(err):\n",
    "    print(iso_list[indx], '\\t', err[indx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
